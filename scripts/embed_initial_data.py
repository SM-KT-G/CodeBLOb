"""
ì´ˆê¸° ì„ë² ë”© ë°ì´í„° ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸

labled_data/ í´ë”ì˜ JSON íŒŒì¼ë“¤ì„ ì½ì–´ì„œ HuggingFace ë¡œì»¬ ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„± í›„ DBì— ì €ì¥
"""
import os
import sys
import time
import json
import argparse
from pathlib import Path
from typing import List, Dict
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python pathì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from sentence_transformers import SentenceTransformer
from dotenv import load_dotenv
from scripts.embedding_utils import (
    find_json_files,
    load_json_file,
    extract_embedding_text,
    extract_metadata,
    map_domain,
    validate_data,
    estimate_tokens,
)
from backend.db.connect import DatabaseConnection
from backend.utils.logger import setup_logger, log_exception

# ë¡œê±° ì„¤ì •
logger = setup_logger(__name__)


class EmbeddingProcessor:
    """ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, dry_run: bool = False, include_qa: bool = False, model_name: str = "intfloat/multilingual-e5-large"):
        """
        Args:
            dry_run: Trueë©´ ì‹¤ì œ DB ì €ì¥ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ
            include_qa: QA ë°ì´í„°ë„ ì„ë² ë”©ì— í¬í•¨í• ì§€ ì—¬ë¶€
            model_name: HuggingFace ëª¨ë¸ ì´ë¦„
        """
        self.dry_run = dry_run
        self.include_qa = include_qa
        self.model_name = model_name
        
        # HuggingFace ëª¨ë¸ ë¡œë“œ (GPU ì‚¬ìš©)
        import torch
        device = 'mps' if torch.backends.mps.is_available() else 'cpu'
        logger.info(f"ğŸ¤— HuggingFace ëª¨ë¸ ë¡œë“œ ì¤‘: {model_name} (device: {device})")
        self.model = SentenceTransformer(model_name, device=device)
        logger.info(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ì°¨ì›: {self.model.get_sentence_embedding_dimension()}, device: {device})")
        
        # DB ì—°ê²° (dry_runì´ ì•„ë‹ ë•Œë§Œ)
        self.db = None if dry_run else DatabaseConnection()
        
        # í†µê³„
        self.stats = {
            "total": 0,
            "success": 0,
            "skipped": 0,
            "failed": 0,
            "total_tokens": 0,
        }
    
    def create_embedding(self, text: str) -> List[float]:
        """
        HuggingFace ëª¨ë¸ë¡œ ì„ë² ë”© ìƒì„±
        
        Args:
            text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
            
        Returns:
            ì„ë² ë”© ë²¡í„° (dimension 1024)
        """
        try:
            # E5 ëª¨ë¸ì€ ì¿¼ë¦¬ì— "query: " ì ‘ë‘ì‚¬ í•„ìš” (ë¬¸ì„œëŠ” í•„ìš” ì—†ìŒ)
            # ìš°ë¦¬ëŠ” ë¬¸ì„œ ì„ë² ë”©ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
            embedding = self.model.encode(text, convert_to_numpy=True)
            
            # í† í° ìˆ˜ ì¶”ì • (í†µê³„ìš©)
            tokens_used = estimate_tokens(text)
            self.stats["total_tokens"] += tokens_used
            
            # ì°¨ì› ê²€ì¦
            expected_dim = self.model.get_sentence_embedding_dimension()
            if len(embedding) != expected_dim:
                raise ValueError(f"ì˜ëª»ëœ ì„ë² ë”© ì°¨ì›: {len(embedding)}, ì˜ˆìƒ: {expected_dim}")
            
            return embedding.tolist()
            
        except Exception as e:
            log_exception(e, {"text_length": len(text)}, logger)
            raise
    
    def check_document_exists(self, document_id: str) -> bool:
        """
        DBì— ì´ë¯¸ ì¡´ì¬í•˜ëŠ” documentì¸ì§€ í™•ì¸
        
        Args:
            document_id: ë¬¸ì„œ ID
            
        Returns:
            ì¡´ì¬ ì—¬ë¶€
        """
        if self.dry_run or not self.db:
            return False
        
        try:
            with self.db.pool.connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(
                        "SELECT 1 FROM tourism_data WHERE document_id = %s",
                        (document_id,)
                    )
                    return cur.fetchone() is not None
        except Exception as e:
            log_exception(e, {"document_id": document_id}, logger)
            return False
    
    def insert_document(
        self, 
        document_id: str, 
        domain: str, 
        title: str, 
        content: str, 
        embedding: List[float],
        metadata: Dict
    ):
        """
        DBì— ë¬¸ì„œ ì‚½ì…
        
        Args:
            document_id: ë¬¸ì„œ ID
            domain: ë„ë©”ì¸ (ENUM)
            title: ì œëª©
            content: ë³¸ë¬¸
            embedding: ì„ë² ë”© ë²¡í„°
            metadata: ë©”íƒ€ë°ì´í„° JSON
        """
        if self.dry_run:
            logger.info(f"[DRY-RUN] INSERT: {document_id} (domain={domain})")
            return
        
        try:
            with self.db.pool.connection() as conn:
                with conn.cursor() as cur:
                    cur.execute(
                        """
                        INSERT INTO tourism_data 
                        (document_id, domain, title, content, embedding, metadata, created_at)
                        VALUES (%s, %s, %s, %s, %s, %s, NOW())
                        """,
                        (
                            document_id,
                            domain,
                            title,
                            content,
                            embedding,
                            json.dumps(metadata, ensure_ascii=False)  # dict â†’ JSON ë¬¸ìì—´ ë³€í™˜
                        )
                    )
                    conn.commit()
            logger.info(f"âœ… ì €ì¥ ì™„ë£Œ: {document_id}")
            
        except Exception as e:
            log_exception(e, {
                "document_id": document_id,
                "domain": domain,
                "title": title
            }, logger)
            raise
    
    def process_file(self, file_path: Path, folder_name: str) -> bool:
        """
        ë‹¨ì¼ JSON íŒŒì¼ ì²˜ë¦¬
        
        Args:
            file_path: JSON íŒŒì¼ ê²½ë¡œ
            folder_name: í´ë”ëª… (TL_FOOD ë“±)
            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            # 1. JSON ë¡œë“œ
            data = load_json_file(file_path)
            
            # 2. ìœ íš¨ì„± ê²€ì¦
            if not validate_data(data):
                logger.warning(f"âš ï¸  ìœ íš¨í•˜ì§€ ì•Šì€ ë°ì´í„°: {file_path.name}")
                return False
            
            data_info = data["data_info"]
            document_id = data_info["documentID"]
            
            # 3. ì¤‘ë³µ ì²´í¬
            if self.check_document_exists(document_id):
                logger.info(f"â­ï¸  ì´ë¯¸ ì¡´ì¬: {document_id}")
                self.stats["skipped"] += 1
                return True
            
            # 4. ë„ë©”ì¸ ë§¤í•‘
            domain_kr = data_info.get("domain", "")
            domain = map_domain(domain_kr, folder_name)
            
            # 5. ì„ë² ë”© í…ìŠ¤íŠ¸ ì¶”ì¶œ
            embedding_text = extract_embedding_text(data, include_qa=self.include_qa)
            
            if not embedding_text.strip():
                logger.warning(f"âš ï¸  ë¹ˆ í…ìŠ¤íŠ¸: {document_id}")
                return False
            
            # 6. ì„ë² ë”© ìƒì„±
            embedding = self.create_embedding(embedding_text)
            
            # 7. ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ìµœì†Œí™”: source_url, sourceë§Œ)
            metadata = extract_metadata(data)
            
            # 8. DB ì €ì¥
            self.insert_document(
                document_id=document_id,
                domain=domain,
                title=data_info.get("title", ""),
                content=data.get("text", ""),
                embedding=embedding,
                metadata=metadata
            )
            
            return True
            
        except Exception as e:
            log_exception(e, {"file": str(file_path)}, logger)
            return False
    
    def process_batch(self, files: List[tuple], batch_size: int = 1000):
        """
        íŒŒì¼ ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            files: (íŒŒì¼ê²½ë¡œ, í´ë”ëª…) íŠœí”Œ ë¦¬ìŠ¤íŠ¸
            batch_size: ë°°ì¹˜ í¬ê¸° (ë¡œì»¬ ëª¨ë¸ì´ë¯€ë¡œ 1000ê°œë¡œ ì¦ê°€)
        """
        total = len(files)
        
        for i, (file_path, folder_name) in enumerate(files, 1):
            logger.info(f"[{i}/{total}] ì²˜ë¦¬ ì¤‘: {file_path.name}")
            
            success = self.process_file(file_path, folder_name)
            
            if success:
                self.stats["success"] += 1
            else:
                self.stats["failed"] += 1
            
            # ë°°ì¹˜ ë‹¨ìœ„ë¡œ ì ì‹œ ëŒ€ê¸° (API rate limit ë°©ì§€)
            if i % batch_size == 0:
                logger.info(f"ë°°ì¹˜ {i//batch_size} ì™„ë£Œ, 1ì´ˆ ëŒ€ê¸°...")
                time.sleep(1)
    
    def print_summary(self, elapsed_time: float):
        """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        logger.info("=" * 60)
        logger.info("ğŸ“Š ì„ë² ë”© ì²˜ë¦¬ ì™„ë£Œ")
        logger.info("=" * 60)
        logger.info(f"ëª¨ë¸: {self.model_name}")
        logger.info(f"ì´ íŒŒì¼ ìˆ˜: {self.stats['total']}")
        logger.info(f"âœ… ì„±ê³µ: {self.stats['success']}")
        logger.info(f"â­ï¸  ìŠ¤í‚µ: {self.stats['skipped']}")
        logger.info(f"âŒ ì‹¤íŒ¨: {self.stats['failed']}")
        logger.info(f"ğŸ”¢ ì´ í† í° (ì¶”ì •): {self.stats['total_tokens']:,}")
        logger.info(f"ğŸ’° ë¹„ìš©: $0 (ë¡œì»¬ ëª¨ë¸)")
        logger.info(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
        logger.info("=" * 60)
    
    def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self.db:
            self.db.close()


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="ì´ˆê¸° ì„ë² ë”© ë°ì´í„° ì²˜ë¦¬")
    parser.add_argument(
        "--data-dir",
        type=Path,
        default=project_root / "labled_data",
        help="ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸: labled_data/)"
    )
    parser.add_argument(
        "--domains",
        type=str,
        help="ì²˜ë¦¬í•  ë„ë©”ì¸ (ì‰¼í‘œ êµ¬ë¶„, ì˜ˆ: food,stay)"
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="ì‹¤ì œ DB ì €ì¥ ì—†ì´ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰"
    )
    parser.add_argument(
        "--include-qa",
        action="store_true",
        help="QA ë°ì´í„°ë„ ì„ë² ë”©ì— í¬í•¨"
    )
    parser.add_argument(
        "--model",
        type=str,
        default="intfloat/multilingual-e5-large",
        help="HuggingFace ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: intfloat/multilingual-e5-large)"
    )
    
    args = parser.parse_args()
    
    # í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    logger.info("ğŸš€ ì´ˆê¸° ì„ë² ë”© ì²˜ë¦¬ ì‹œì‘ (HuggingFace ë¡œì»¬ ëª¨ë¸)")
    logger.info(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {args.data_dir}")
    logger.info(f"ëª¨ë¸: {args.model}")
    logger.info(f"ë“œë¼ì´ëŸ° ëª¨ë“œ: {args.dry_run}")
    logger.info(f"QA í¬í•¨: {args.include_qa}")
    
    # ë°ì´í„° ë””ë ‰í† ë¦¬ í™•ì¸
    if not args.data_dir.exists():
        logger.error(f"âŒ ë°ì´í„° ë””ë ‰í† ë¦¬ ì—†ìŒ: {args.data_dir}")
        sys.exit(1)
    
    # ë„ë©”ì¸ íŒŒì‹±
    domains = None
    if args.domains:
        domains = [d.strip() for d in args.domains.split(",")]
        logger.info(f"í•„í„°ë§ ë„ë©”ì¸: {domains}")
    
    try:
        # 1. JSON íŒŒì¼ íƒìƒ‰
        logger.info("ğŸ“‚ JSON íŒŒì¼ íƒìƒ‰ ì¤‘...")
        files = find_json_files(args.data_dir, domains)
        logger.info(f"ì´ {len(files)}ê°œ íŒŒì¼ ë°œê²¬")
        
        if not files:
            logger.warning("âš ï¸  ì²˜ë¦¬í•  íŒŒì¼ ì—†ìŒ")
            return
        
        # 2. ì„ë² ë”© ì²˜ë¦¬
        start_time = time.time()
        
        processor = EmbeddingProcessor(
            dry_run=args.dry_run,
            include_qa=args.include_qa,
            model_name=args.model
        )
        processor.stats["total"] = len(files)
        
        processor.process_batch(files)
        
        # 3. ê²°ê³¼ ì¶œë ¥
        elapsed_time = time.time() - start_time
        processor.print_summary(elapsed_time)
        
        # 4. ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        processor.close()
        
        # 5. ì¢…ë£Œ ì½”ë“œ
        if processor.stats["failed"] > 0:
            logger.warning(f"âš ï¸  {processor.stats['failed']}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
            sys.exit(1)
        
        logger.info("âœ… ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!")
        
    except KeyboardInterrupt:
        logger.warning("âš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
        sys.exit(1)
    except Exception as e:
        log_exception(e, {}, logger)
        sys.exit(1)


if __name__ == "__main__":
    main()
